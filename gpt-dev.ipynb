{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e081fadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ebea9f68f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640ea277",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "277eb8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters is: 1115394\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of characters is: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf9b592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6efc979d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 e\n",
      "31 d\n",
      "32  \n",
      "33 a\n",
      "34 n\n",
      "35 y\n",
      "36  \n",
      "37 f\n",
      "38 u\n",
      "39 r\n",
      "40 t\n",
      "41 h\n",
      "42 e\n",
      "43 r\n",
      "44 ,\n",
      "45  \n",
      "46 h\n",
      "47 e\n",
      "48 a\n",
      "49 r\n",
      "50  \n",
      "51 m\n",
      "52 e\n",
      "53  \n",
      "54 s\n",
      "55 p\n",
      "56 e\n",
      "57 a\n",
      "58 k\n",
      "59 .\n",
      "60 \n",
      "\n",
      "61 \n",
      "\n",
      "62 A\n",
      "63 l\n",
      "64 l\n",
      "65 :\n",
      "66 \n",
      "\n",
      "67 S\n",
      "68 p\n",
      "69 e\n"
     ]
    }
   ],
   "source": [
    "for i in range(30, 70):\n",
    "    print(i,text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb1212ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd5ba650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '3',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f48d412f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "s_to_i = {s:i for i,s in enumerate(chars)}\n",
    "i_to_s = {i:s for i,s in enumerate(chars)}\n",
    "encode = lambda s: [s_to_i[c] for c in s]\n",
    "decode = lambda l: ''.join([i_to_s[i] for i in l])\n",
    "\n",
    "print(encode(\"hello there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba7d550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "840d36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26da33f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([18]) the target is 47.\n",
      "When input is tensor([18, 47]) the target is 56.\n",
      "When input is tensor([18, 47, 56]) the target is 57.\n",
      "When input is tensor([18, 47, 56, 57]) the target is 58.\n",
      "When input is tensor([18, 47, 56, 57, 58]) the target is 1.\n",
      "When input is tensor([18, 47, 56, 57, 58,  1]) the target is 15.\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is 47.\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is 58.\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"When input is {context} the target is {target}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d2f01a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1337)\n",
    "# batch_size = 4\n",
    "# block_size = 8\n",
    "\n",
    "# def get_batch(split):\n",
    "#     data = train_data if split == 'train' else val_data\n",
    "#     ix = torch.randint(len(data) - block_size, (batch_size,)) #[num, num, ... 8 times]\n",
    "#     x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "#     y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "#     return x,y\n",
    "\n",
    "# xb, yb = get_batch('train')\n",
    "# print(f'Inputs: {xb} \\nInput Shape: {xb.shape}')\n",
    "# print(f\"Targets: {yb} \\nTarget Shape: {yb.shape}\")\n",
    "# print('-------')\n",
    "\n",
    "# for b in range(batch_size): #batch dimension\n",
    "#     for t in range(block_size): #time dimension\n",
    "#         context = xb[b, :t+1]\n",
    "#         target = yb[b,t]\n",
    "#         print(f\"When input is {context.tolist()} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85528bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "batch_size = 32       #no. of independent seq we process in parallel\n",
    "block_size = 8        #max context length for pred\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca8fde2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) #[num, num, ... 8 times]\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y =  x.to(device), y.to(device)\n",
    "    return x,y\n",
    "\n",
    "@torch.no_grad() # don't call .backward when doing estimate_loss()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37bf2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    #one head of self-attention\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__() #nn.Module's __init__\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size))) #lower triangular matrix of ones\n",
    "\n",
    "    def forward(self, x): #in karpathy's tutorials he assumes C and head_size are same but C is actually embedding dimension\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x) #(B,T,head_size)\n",
    "        q = self.query(x) #(B,T,head_size)\n",
    "        wei = q @ k.transpose(-2,-1) * (k.shape[-1] **-0.5) #(B,T,head_size) @ (B,head_size,T) --> (B,T,T) *C**-0.5 is done to ensure that before softmax the variance is 1\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) #(B,T,T) -inf so that softmax outputs 0 for them\n",
    "        wei = F.softmax(wei, dim=-1) #(B,T,T)\n",
    "        v = self.value(x) #(B,T,head_size)\n",
    "        out = wei @ v #(B,T,head_size)\n",
    "        #so out[0,2,7] means for the first batch the 3rd letter 8th dimension is the weighted sum of 8th dimesion of the value vectors for letters 0,1,2 \n",
    "        #where the weights are computed using the query of token 2 and keys of tokens 0-2\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1a5875",
   "metadata": {},
   "source": [
    "Multi-head attention lets the model attend to different types of relationships simultaneously, which a single large attention head fundamentally cannot do (even though the number of dimensions match) because single head produces only one attention atrix and just one attention matrix cannout represent multiple independent attention patterns.\n",
    "\n",
    "All the dimensions (say 32) of each letter get the same attention (or weights) in self attention but by dividng it into multiple heads of 8 dims each we can give these 4 batches of 8 dims different sets of attentions (or weights).\n",
    "\n",
    "Assume that first head is for syntax and second head is for semantics. Say letter 3 must attend strongly (say 0.75) for syntax and weakly (say 0.03) for semantics to letter 1 and strongly (say 0.70) to letter 1 for semantics and weakly (say 0.05) for syntax to letter 2. This won't be possible in single head of 32 because the entire letter (or all 32 dimensions) will get attented to by the same weight and the sum of weights of syntax attention and semantics attention would be greater than 1 which is not possible because of softmaxing all 32 dims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e971e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    #multiple heads of self-attention in parallel\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__() #nn.Module's __init__\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd) #this is done so that the concatenated head outputs back into the model's working \n",
    "        #embedding space so that we can add each dimension to x's dimension while adding residual connections (to prevent adding RGB to HSV)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fb81a5",
   "metadata": {},
   "source": [
    "Self-attention decides how tokens communicate, but the feed-forward network is what actually computes meaningful representations from that information.\n",
    "\n",
    "In other words: Self-attention gathers information from other tokens, while the feed-forward network turns that information into useful features (this mainly happens because of the presence of non linearity in ffn). After FFN the token would have interpreted the context it received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31d845e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    #a linear layer followed by a non-linearity\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__() #nn.Module's __init__\n",
    "        self.net = nn.Sequential(nn.Linear(n_embd, 4*n_embd), nn.ReLu(), nn.Linear(4*n_embd, n_embd),)\n",
    "        #the last linear layer is what allows the FFN to recombine the ReLU-activated features into a new learned representation that can be added back via the residual connection\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aac77c",
   "metadata": {},
   "source": [
    "We need to add residual connections because it ensures that gradients cannot vanish completely and information always flows backward.\n",
    "\n",
    "Early in training, attention weights are nar-random and wihtout residuals, representations can collapse. Rediduals ensure that each layer can only improve or slightly adjust the representation.\n",
    "\n",
    "Residuals therefore help with stable optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa30dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    #Transformer block: communication followed by computation\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__() #nn.Module's __init__\n",
    "        head_size = n_embd//n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd) #normalises overall the dimensions for 1 token\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x)) #the x + is to add the residual\n",
    "        x = x + self.ffwd(self.ln1(x)) #same as above\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72deae7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'ReLu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 47\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m idx\n\u001b[0;32m     46\u001b[0m xb, yb \u001b[38;5;241m=\u001b[39m get_batch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBigramLanguageModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m m \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     49\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m m(xb,yb)\n",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m, in \u001b[0;36mBigramLanguageModel.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(block_size, n_embd)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# self.sa_heads = MultiHeadAttention(4,n_embd//4) #i.e., 4 heads of 8-dimensional self-attention\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# self.ffwd = FeedForward(n_embd)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[43mBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_embd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_head\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m, Block(n_embd, n_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m), Block(n_embd, n_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m), Block(n_embd, n_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m),)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(n_embd, vocab_size)\n",
      "Cell \u001b[1;32mIn[18], line 8\u001b[0m, in \u001b[0;36mBlock.__init__\u001b[1;34m(self, n_embd, n_head)\u001b[0m\n\u001b[0;32m      6\u001b[0m head_size \u001b[38;5;241m=\u001b[39m n_embd\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mn_head\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa \u001b[38;5;241m=\u001b[39m MultiHeadAttention(n_head, head_size)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffwd \u001b[38;5;241m=\u001b[39m \u001b[43mFeedForward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_embd\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m, in \u001b[0;36mFeedForward.__init__\u001b[1;34m(self, n_embd)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_embd):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m() \u001b[38;5;66;03m#nn.Module's __init__\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(nn\u001b[38;5;241m.\u001b[39mLinear(n_embd, \u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39mn_embd), \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReLu\u001b[49m(), nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39mn_embd, n_embd),)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'ReLu'"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__() #nn.Module's __init__\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        # self.sa_heads = MultiHeadAttention(4,n_embd//4) #i.e., 4 heads of 8-dimensional self-attention\n",
    "        # self.ffwd = FeedForward(n_embd)\n",
    "        self.blocks = nn.Sequential(Block(n_embd, n_head=4), Block(n_embd, n_head=4), Block(n_embd, n_head=4), Block(n_embd, n_head=4), nn.LayerNorm(n_embd),)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        \n",
    "        B,T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C) (number of batches or sequences in parallel, number of tokens being processed, embedding dimension)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) #(T,C)\n",
    "        x = tok_emb + pos_emb #(B,T,C)\n",
    "        # x = self.sa_heads(x) #apply one head of self-attention (B,T,C)\n",
    "        # x = self.ffwd(x) #(B,T,C)\n",
    "        x = self.blocks(x) #(B,T,C)\n",
    "        logits = self.lm_head(x) #(B,T,C) here C is vocab size. C was 32 earlier now it is 65 as we want logits here\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond) #equivalent to self.forward(idx, targets=None) so (B,T,C)\n",
    "            logits = logits[:, -1, :] #select last timestamp so it is (B,C), Given the seq so far, how likely is each possible next token\n",
    "            probs = F.softmax(logits, dim=-1) #(B,C)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) #(B,1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1) #(B,T+1)\n",
    "        \n",
    "        return idx\n",
    "\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "logits, loss = m(xb,yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada496fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: train loss 4.1730, val loss 4.1752\n",
      "Step 500: train loss 2.6892, val loss 2.7086\n",
      "Step 1000: train loss 2.5400, val loss 2.5657\n",
      "Step 1500: train loss 2.4709, val loss 2.4806\n",
      "Step 2000: train loss 2.4102, val loss 2.4210\n",
      "Step 2500: train loss 2.3728, val loss 2.3890\n",
      "Step 3000: train loss 2.3458, val loss 2.3607\n",
      "Step 3500: train loss 2.3168, val loss 2.3399\n",
      "Step 4000: train loss 2.3113, val loss 2.2999\n",
      "Step 4500: train loss 2.2877, val loss 2.2998\n",
      "\n",
      "Whent ak bridcowilen, son, be madiren bobe doe.\n",
      "Shert the dalitauss:\n",
      "Warthie us hat vet?\n",
      "Fedtlay anen wice my.\n",
      "\n",
      "Hald pom onou waownt, tof it he me mil; dill, bes ifee sen cin lat Het, rov te, and Whe nour iserabe!\n",
      " lelind peall lish, cecriry prupr aiss hew you lomave norf petelives\n",
      "Mome.\n",
      "Whod moth kleo Winsh wher eiiby we ath fourive cen, ime sto-o--\n",
      "Ar-xThe\n",
      "To kud nonruptef sor; ig. Whe:\n",
      "Et Cey ale of,\n",
      "Tish Pre?\n",
      "\n",
      "WISom.\n",
      "\n",
      "He-Nube!\n",
      "\n",
      "Wied is wardsal the E'D sush in coukrear tey Iry the han your wi\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "     #every now and then evaluate the loss on train and val sets\n",
    "     if iter % eval_interval == 0:\n",
    "          losses = estimate_loss()\n",
    "          print(f\"Step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "     xb, yb = get_batch('train')\n",
    "     logits, loss = model(xb, yb)\n",
    "     optimizer.zero_grad(set_to_none = True)\n",
    "     loss.backward()\n",
    "     optimizer.step()\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist())) #[0] becasue we are taking the first element from generate's batch dim (albeit the batch dimension is only 1 rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad38957c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# for steps in range(10000):\n",
    "#     xb, yb = get_batch('train')\n",
    "#     logits, loss = m(xb,yb)\n",
    "#     optimizer.zero_grad(set_to_none=True)\n",
    "#     loss.backward()\n",
    "#     optimizer.step() #upgrade gradient\n",
    "# print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe78dc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open3d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
